<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>机器学习第四章 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="逻辑回归4.1 分类问题在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。分类问题的例子有：判断一封电子邮件是否是垃圾邮件；判断一次金融交易是否是欺诈等等。我们从二元的分类问题开始讨论。我们将因变量（dependant variable）可能属于的两个类分别称为负向类（negative class）和正向类（positive class），则因变量$$ y∈{0,1} $$，其">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习第四章">
<meta property="og:url" content="http://yoursite.com/2018/07/08/机器学习第四章/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="逻辑回归4.1 分类问题在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。分类问题的例子有：判断一封电子邮件是否是垃圾邮件；判断一次金融交易是否是欺诈等等。我们从二元的分类问题开始讨论。我们将因变量（dependant variable）可能属于的两个类分别称为负向类（negative class）和正向类（positive class），则因变量$$ y∈{0,1} $$，其">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://iajqs.github.io/img/oneLine.jpg">
<meta property="og:image" content="https://iajqs.github.io/img/oneLine2.png">
<meta property="og:image" content="https://iajqs.github.io/img/sigmoid.jpg">
<meta property="og:image" content="https://iajqs.github.io/img/oneLine3.jpg">
<meta property="og:image" content="https://iajqs.github.io/img/oneLine4.jpg">
<meta property="og:image" content="https://iajqs.github.io/img/costFunction4.jpg">
<meta property="og:image" content="https://iajqs.github.io/img/costFunction5.png">
<meta property="og:image" content="https://iajqs.github.io/img/cost.png">
<meta property="og:image" content="https://iajqs.github.io/img/costFunction6.jpg">
<meta property="og:image" content="https://iajqs.github.io/img/costFunction7.png">
<meta property="og:image" content="https://iajqs.github.io/img/costFunction8.png">
<meta property="og:image" content="https://iajqs.github.io/img/GradientDescentforMultiple1.png">
<meta property="og:image" content="https://iajqs.github.io/img/GradientDescentforMultiple3.png">
<meta property="og:image" content="https://iajqs.github.io/img/multiclass_classification.png">
<meta property="og:image" content="https://iajqs.github.io/img/multiclass_classification2.png">
<meta property="og:updated_time" content="2018-07-11T08:58:03.134Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习第四章">
<meta name="twitter:description" content="逻辑回归4.1 分类问题在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。分类问题的例子有：判断一封电子邮件是否是垃圾邮件；判断一次金融交易是否是欺诈等等。我们从二元的分类问题开始讨论。我们将因变量（dependant variable）可能属于的两个类分别称为负向类（negative class）和正向类（positive class），则因变量$$ y∈{0,1} $$，其">
<meta name="twitter:image" content="https://iajqs.github.io/img/oneLine.jpg">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-机器学习第四章" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/08/机器学习第四章/" class="article-date">
  <time datetime="2018-07-08T07:58:30.000Z" itemprop="datePublished">2018-07-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习第四章
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><h2 id="4-1-分类问题"><a href="#4-1-分类问题" class="headerlink" title="4.1 分类问题"></a>4.1 分类问题</h2><p>在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。分类问题的例子有：判断一封电子邮件是否是垃圾邮件；判断一次金融交易是否是欺诈等等。<br>我们从二元的分类问题开始讨论。<br>我们将因变量（dependant variable）可能属于的两个类分别称为负向类（negative class）和正向类（positive class），则因变量$$ y∈{0,1} $$，其中0表示负向类，1表示正向类。</p>
<h2 id="4-2-分类问题建模"><a href="#4-2-分类问题建模" class="headerlink" title="4.2 分类问题建模"></a>4.2 分类问题建模</h2><p>回顾在一开始提到的乳腺癌分类问题，我们可以用线性回归的方法求出适合数据的一条直线：<br><img src="https://iajqs.github.io/img/oneLine.jpg" alt=""><br>根据线性回归模型我们只能预测连续的值，然而对于分类问题，我们需要输出0或1，我们可以预测：（我想这里有个值得注意的点，线性回归是解决回归问题，逻辑回归是解决分类问题，至于逻辑回归这个名字的命名原因， 是由于其中使用了一个sigmoid函数作为中间结果，而这个中间结果就是一个连续的值。）<br>-当h_θ大于等0.5时，预测y=1<br>-当h_θ小于0.5时，预测y=0<br>对于上图所示的数据，这样的一个线性模型似乎能很好地完成分类任务。假使我们又预测到一个非常大尺寸的恶性肿瘤，将其作为实例加入到我们的训练集中来，这将使得我们获得一条新的直线。<br><img src="https://iajqs.github.io/img/oneLine2.png" alt=""><br>这时，再使用0.5作为阈值来预测肿瘤是良性还是恶性便不合适了。可以看出，线性回归模型，因为其预测的值可以超过[0,1]的范围，并不适合解决这样的问题。<br>我们引入一个新的模型，逻辑回归，该模型的输出变量范围始终在0到1之间。<br>逻辑回归模型的假设是：$$ h_θ(X) = g(θ^TX) $$<br>其中：<br>-X代表特征向量<br>-g代表逻辑函数（logistic function）是一个常用的逻辑函数为s形函数（Sigmoid function），公式为$$ g(z) = {1 \over 1+e^{-z}} $$<br>该函数的图像为：<br><img src="https://iajqs.github.io/img/sigmoid.jpg" alt=""><br>合起来，我们得到逻辑回归模型的假设：<br>$$<br>h_θ(x) = {1 \over 1+e^{-θ^TX}}<br>$$对于给定的输入<br>对模型的理解：<br>$$ h_θ(x) $$的作用是，对于给定的输入变量，根据选择的参数计算输出变量=1的可能性（estimated probability）即 $$ h_θ(x)=P(y=1|x;θ) $$<br>例如，如果对于给定的x，通过已经确定的参数计算得出$$ h_θ(x) = 0.7 $$，则表示有百分之70的几率y为正向类，相应地y为负向类的几率为<code>1-0.7=0.3.</code></p>
<h2 id="4-3判定边界"><a href="#4-3判定边界" class="headerlink" title="4.3判定边界"></a>4.3判定边界</h2><p>在逻辑回归中，我们预测：<br>-当h_θ大于等于0.5时，预测y=1<br>-当h_θ小于0.5时，预测y=0<br>根据上面绘制出的S形函数图像，我们知道当<br>-z=0时g(z)=0.5<br>-z&gt;0时g(z)&gt;0.5<br>-z&lt;0时g(z)&lt;0.5<br>又z=θ^TX，即<br>-θ^T大于等于0时，预测y=1<br>-θ^T小于0时，预测y=0<br>现在假设我们有一个模型：$$ h_θ(x)=g(θ_0+θ_1x_1+θ_2x_2) $$并且参数θ是向量[-3 1 1]。<br>则当<code>-3+x_1+x_2</code>大于等于0，即<code>x_1+x_2</code>大于等于3时，模型将预测y=1。<br>我们可以绘制直线<code>x_1+x_2=3</code>，这条线便是我们模型的分界线，将预测为1的区域和预测为0的区域分隔开。<br><img src="https://iajqs.github.io/img/oneLine3.jpg" alt=""><br>即使我们的数据呈现这样的分布情况，怎样的模型才能合适呢？<br><img src="https://iajqs.github.io/img/oneLine4.jpg" alt=""><br>因为需要用曲线才能分隔y=0的区域和y=1的区域，我们需要二次方特征：<br>$$ h_θ(x)=g(θ_0+θ_1x_1+θ_2x_2+θ_3x_1^2+θ_4x_2^2) $$<br>假设参数是[-1 0 0 1 1]，则我们得到的判定边界恰好是圆点在原点且半径为1的圆形。<br>我们可以用哪个非常复杂的模型来适应非常复杂形状的判定边界。</p>
<h2 id="4-4-代价函数"><a href="#4-4-代价函数" class="headerlink" title="4.4 代价函数"></a>4.4 代价函数</h2><p>对于线性回归模型，我们定义的代价函数是所有模型误差的平方和。理论上来说，我们也可以对逻辑回归模型沿用这个定义，但是问题在于，当我们将$$ h_θ(X)={1 \over 1+e^{-θ^TX}} $$带入到这样定义了的代价函数中，我们得到的代价函数将是一个非凸函数(non-convex function)。<br><img src="https://iajqs.github.io/img/costFunction4.jpg" alt=""><br>这意味着我们的代价函数有很多局部最小值，这将影响梯度下降法寻找全局最小值。因此我们重新定义逻辑回归的代价函数为：<br><img src="https://iajqs.github.io/img/costFunction5.png" alt=""><br>其中<br><img src="https://iajqs.github.io/img/cost.png" alt=""><br>$$ h_θ(x) $$ 与 $$ Cost(h_θ(x),y) $$之间的关系如下图所示：<br><img src="https://iajqs.github.io/img/costFunction6.jpg" alt=""><br>这样构建的$$ Cost(h_θ(x),y) $$函数的特点是：当实际的y=1且$$ h_θ $$也为1时误差为0，当y=1但$$ h_θ $$不为1时误差随着$$ h_θ $$的变小而变大；当实际的y=0且$$h_θ$$也为0时代价为0，当y=0但$$ h_θ $$不为0时的误差随着$$ h_θ $$的变大而变大。<br>将构建的$$ Cost(h_θ(x),y) $$简化如下：<br><img src="https://iajqs.github.io/img/costFunction7.png" alt=""><br>带入代价函数得到：<br><img src="https://iajqs.github.io/img/costFunction8.png" alt=""><br>在得到这样一个代价函数以后，我们便可以用梯度下降算法来求得能使代价函数最小的参数了。算法为：<br><img src="https://iajqs.github.io/img/GradientDescentforMultiple1.png" alt=""><br><br>求导后得到：<br><img src="https://iajqs.github.io/img/GradientDescentforMultiple3.png" alt=""><br><br>注：虽然得到的梯度下降算法表面上看上去与线性回归的梯度下降法一样，但是这里的$$ h_θ(x)=g(θ^TX)$$与线性回归中不同，所以实际上是不一样的，另外，在运行梯度下降算法之前，进行特征缩放依旧是非常必要的。<br>一些梯度下降算法之外的选择：<br>除了梯度下降算法以外还有一些常被用来令代价函数最小的算法，这些算法更加复杂和优越，而且通常不需要人工选择学习率，通常比梯度下降算法要更加快速，这些算法有：共轭梯度（Conjugate Gradient），局部优化法（Broyden fletcher goldfarb shann， BFGS）和有限内存局部优化法（LBFGS）<br>fminunc 是 matlab 和 octave 中都带的一个最小值优化函数，使用时我们需要提供代价函数<br>和每个参数的求导，下面是 octave 中使用 fminunc 函数的代码示例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">function [jVal, gradient] = costFunction(theta)</span><br><span class="line">jVal = [...code to compute J(theta)...];</span><br><span class="line">gradient = [...code to compute derivative of J(theta)...];</span><br><span class="line">end</span><br><span class="line">options = optimset(&apos;GradObj&apos;, &apos;on&apos;, &apos;MaxIter&apos;, &apos;100&apos;);</span><br><span class="line">initialTheta = zeros(2,1);</span><br><span class="line">[optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);</span><br></pre></td></tr></table></figure></p>
<h2 id="4-5-多类分类"><a href="#4-5-多类分类" class="headerlink" title="4.5 多类分类"></a>4.5 多类分类</h2><p>多类分类问题中，我们的训练集中有多个类（&gt;2），我们无法仅仅用一个二元变量（0或1）来做判断依据，例如我们要预测天气情况分四中类型：晴天，多云，下雨或下雪。<br>下面是一个多分类问题可能的情况。<br><img src="https://iajqs.github.io/img/multiclass_classification.png" alt=""><br>一种解决这类问题的途径是采用一对多（One-vs-All）方法。在一对多方法中，我们将多类分类问题转化成二元分类问题。为了能实现这样的转变，我们将多个类中的一个类标记为正向类(y=1)，然后将其他所有类都标记为负向类，这个模型记作$$ h_θ^{(1)}(x) $$。接着，类似地我们选择另一类类标记为正向类（y=2），再将其他类都标记为负向类，将这个模型记作$$ h_θ^{(2)}(x) $$，以此类推。<br>最后我们得到一系列的模型标记为$$ h-θ^{i}（x）=p(y=i|x;θ) $$ 其中i=(1,2,3,…,k)<br><img src="https://iajqs.github.io/img/multiclass_classification2.png" alt=""><br>最后，在我们需要做预测时，我们将所有的分类机制都运行一遍，然后对每一个输入变量，都选择最高可能性的输出变量。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>黄海广博士的笔记：<a href="https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes/blob/master/markdown/week1.md" target="_blank" rel="noopener">https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes/blob/master/markdown/week1.md</a><br>小小人_V 的个人笔记 ​ <a href="https://mooc.guokr.com/note/12/" target="_blank" rel="noopener">https://mooc.guokr.com/note/12/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/08/机器学习第四章/" data-id="cjjgw8789000i2gnwgo5yb09y" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/07/10/机器学习第五章/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          机器学习第五章
        
      </div>
    </a>
  
  
    <a href="/2018/07/06/机器学习第三章/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">机器学习第三章</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/区块链/">区块链</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/深度学习/">深度学习</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/区块链/" style="font-size: 10px;">区块链</a> <a href="/tags/机器学习/" style="font-size: 20px;">机器学习</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/07/11/机器学习第十章/">机器学习第十章</a>
          </li>
        
          <li>
            <a href="/2018/07/10/机器学习第五章/">机器学习第五章</a>
          </li>
        
          <li>
            <a href="/2018/07/08/机器学习第四章/">机器学习第四章</a>
          </li>
        
          <li>
            <a href="/2018/07/06/机器学习第三章/">机器学习第三章</a>
          </li>
        
          <li>
            <a href="/2018/07/06/机器学习第二章/">机器学习第二章</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>